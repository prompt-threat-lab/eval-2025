# Jailbreak Evaluation Dataset (2025)

This repository contains supplementary materials for the paper:

**"Robustness of Modern LLMs Against Jailbreaking:  
Defensive Strategies for Cybersecurity-Relevant Use Cases"**  

## 📁 Contents

- `prompts/`: Full list of adversarial prompts, grouped by technique
- `annotations/`: Manual jailbreak success scores (JAS), harm annotations, and inter-rater notes
- `sample_outputs/`: Example outputs
- `README.md`: This file

## 🔗 Citation

If you use this dataset, please cite our paper (DOI coming soon).

## 📬 Contact

For questions, contact [] at [email@example.com]

## 📄 License

CC BY 4.0 – You are free to share and adapt with attribution.
