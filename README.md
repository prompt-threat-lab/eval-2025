# Jailbreak Evaluation Dataset (2025)

This repository contains supplementary materials for the paper:

**"Robustness of Modern LLMs Against Jailbreaking:  
Defensive Strategies for Cybersecurity-Relevant Use Cases"**  

## ğŸ“ Contents

- `prompts/`: Full list of adversarial prompts, grouped by technique
- `annotations/`: Manual jailbreak success scores (JAS), harm annotations, and inter-rater notes
- `sample_outputs/`: Example outputs
- `README.md`: This file

## ğŸ”— Citation

If you use this dataset, please cite our paper (DOI coming soon).

## ğŸ“¬ Contact

For questions, contact [] at [email@example.com]

## ğŸ“„ License

CC BY 4.0 â€“ You are free to share and adapt with attribution.
